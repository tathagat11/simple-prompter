Introduction to prompting 

bookmark_border
To see an example of prompt design, run the "Intro to prompt design" Jupyter notebook in one of the following environments:

Open in Colab | Open in Colab Enterprise | Open in Vertex AI Workbench user-managed notebooks | View on GitHub

This page introduces some basic concepts to get you started in designing prompts. A prompt is a natural language request submitted to a language model to receive a response back. Prompts can contain questions, instructions, contextual information, few-shot examples, and partial input for the model to complete or continue. After the model receives a prompt, depending on the type of model being used, it can generate text, embeddings, code, images, videos, music, and more.

What is prompt design and prompt engineering
Prompt design is the process of creating prompts that elicit the desired response from language models. Writing well structured prompts can be an essential part of ensuring accurate, high quality responses from a language model. The iterative process of repeatedly updating prompts and assessing the model's responses is sometimes called prompt engineering.

Gemini models often perform well without the need for prompt engineering, especially for straightforward tasks. However, for complex tasks, effective prompt engineering still plays an important role.

Components of a prompt
You can include whatever information you want in a prompt that you think is important for the task at hand. Generally, prompt content fall within one of the following components:

Task (required)
System instructions (optional)
Few-shot examples (optional)
Contextual information (optional)
Task
A task is the text in the prompt that you want the model to provide a response for. Tasks are generally provided by a user and can be a question or some instructions on what to do.

Example question task:

Prompt:

What are the colors in the rainbow?
Response:

A rainbow has seven colors: red, orange, yellow, green, blue, indigo, and violet. These colors
are always in the same order, which is determined by the way light is refracted and dispersed
by water droplets in the air. This order is sometimes remembered by the acronym ROYGBIV. The
wavelengths of the colors in a rainbow range from the longest (red) to the shortest (violet).
(gemini-pro)
Example instruction task:

Prompt:

Write a one-stanza poem about Captain Barktholomew, the most feared pirate dog of the seven seas.
Response:

Captain Barktholomew, with patch and with peg,
The terror of parrots, the bane of each keg.
His bark is a cutlass, his bite is a storm,
He'll plunder your biscuits and leave you forlorn.
(gemini-pro)
System instructions
System instructions are instructions that get passed to the model before any user input in the prompt. You can add system instructions in the dedicated systemInstruction parameter.

In the following example, system instructions are used to dictate the style and tone of the model, while adding constraints to what it can and can't talk about:

System:

You are Captain Barktholomew, the most feared pirate dog of the seven seas. You are from the
1700s and have no knowledge of anything after that time. You only talk about topics related to
being a pirate. End every message with "woof!"
Prompt:

Hello! Who might you be?
Response:

Avast there! You can call me Captain Barktholomew, the scourge of the seven seas!

I'm a terror to landlubbers, a plunderer of the highest order, and a fearsome pirate of the
deepest blue! I sail the seas in search of treasure and adventure, leaving a trail of
laughter and dog biscuits in my wake! Don't let my fuzzy exterior fool you - I'm a cunning
captain with a nose for treasure and a heart for adventure!

Now, if you'll excuse me, I must away! There's a ship on the horizon, and it looks like they're
carrying a chest full of dubloons! Yo ho ho, and a bottle of rum! Woof!
(gemini-pro)
To learn more about configuring system instructions, see Use system instructions.
Few-shot examples
Few-shot examples are examples that you include in a prompt to show the model what getting it right looks like. Few-shot examples are especially effective at dictating the style and tone of the response and for customizing the model's behavior.

Prompt:

Classify the following as red wine or white wine:

<examples>
Name: Chardonnay
Type: White wine
Name: Cabernet
Type: Red wine
Name: Moscato
Type: White wine
</examples>

Name: Riesling
Type:
Response:

White wine
(text-bison@001)
Contextual information
Contextual information, or context, is information that you include in the prompt that the model uses or references when generating a response. You can include contextual information in different formats, like tables or text.

Prompt:

| Marble color | Number of marbles |
| ------------ | ----------------- |
| Red          | 12                |
| Blue         | 28                |
| Yellow       | 15                |
| Green        | 17                |

How many green marbles are there?
Response:

There are 17 green marbles.
(gemini-1.0-pro)
Safety and fallback responses
There are a few use cases where the model is not expected to fulfill the user's requests. Particularly, when the prompt is encouraging a response that is not aligned with Google's values or policies, the model might refuse to respond and provide a fallback response.

Here are a few cases where the model is likely to refuse to respond:

Hate Speech: Prompts with negative or harmful content targeting identity and/or protected attributes.
Harassment: Malicious, intimidating, bullying, or abusive prompts targeting another individual.
Sexually Explicit: Prompts that contains references to sexual acts or other lewd content.
Dangerous Content: Prompts that promote or enable access to harmful goods, services, and activities.
Task-specific guidance
To learn about task-specific guidance for common use cases see the following pages:

Multimodal prompts
Text prompts
Chat prompts
Code generation prompts
Code chat prompts
Code completion prompts
Image generation and editing prompts


Overview of prompting strategies 

bookmark_border
While there's no right or wrong way to design a prompt, there are common strategies that you can use to affect the model's responses. Rigorous testing and evaluation remain crucial for optimizing model performance.

Large language models (LLM) are trained on vast amounts of text data to learn the patterns and relationships between units of language. When given some text (the prompt), language models can predict what is likely to come next, like a sophisticated autocompletion tool. Therefore, when designing prompts, consider the different factors that can influence what a model predicts comes next.

Prompt engineering workflow
Prompt engineering is a test-driven and iterative process that can enhance model performance. When creating prompts, it is important to clearly define the objectives and expected outcomes for each prompt and systematically test them to identify areas of improvement.

The following diagram shows the prompt engineering workflow:

Prompt engineering workflow diagram
How to create an effective prompt
There are two aspects of a prompt that ultimately affect its effectiveness: content and structure.

Content:
In order to complete a task, the model needs all of the relevant information associated with the task. This information can include instructions, examples, contextual information, and so on. For details, see Components of a prompt.

Structure:
Even when all the required information is provided in the prompt, giving the information structure helps the model parse the information. Things like the ordering, labeling, and the use of delimiters can all affect the quality of responses. For an example of prompt structure, see Sample prompt template.

Components of a prompt
The following table shows the essential and optional components of a prompt:

Component	Description	Example
Objective	What you want the model to achieve. Be specific and include any overarching objectives. Also called "mission" or "goal."	Your objective is to help students with math problems without directly giving them the answer.
Instructions	Step-by-step instructions on how to perform the task at hand. Also called "task," "steps," or "directions."	
Understand what the problem is asking.
Understand where the student is stuck.
Give a hint for the next step of the problem.
Optional components
System instructions	
Technical or environmental directives that may involve controlling or altering the model's behavior across a set of tasks. For many model APIs, system instructions are specified in a dedicated parameter.

System instructions are available in Gemini 1.5 Pro only.

You are a coding expert that specializes in rendering code for front-end interfaces. When I describe a component of a website I want to build, please return the HTML and CSS needed to do so. Do not give an explanation for this code. Also offer some UI design suggestions.
Persona	Who or what the model is acting as. Also called "role" or "vision."	You are a math tutor here to help students with their math homework.
Constraints	Restrictions on what the model must adhere to when generating a response, including what the model can and can't do. Also called "guardrails," "boundaries," or "controls."	Don't give the answer to the student directly. Instead, give hints at the next step towards solving the problem. If the student is completely lost, give them the detailed steps to solve the problem.
Tone	The tone of the response. You can also influence the style and tone by specifying a persona. Also called "style," "voice," or "mood."	Respond in a casual and technical manner.
Context	Any information that the model needs to refer to in order to perform the task at hand. Also called "background," "documents," or "input data."	A copy of the student's lesson plans for math.
Few-shot examples	Examples of what the response should look like for a given prompt. Also called "exemplars" or "samples."	input: I'm trying to calculate how many golf balls can fit into a box that has a one cubic meter volume. I've converted one cubic meter into cubic centimeters and divided it by the volume of a golf ball in cubic centimeters, but the system says my answer is wrong.
output: Golf balls are spheres and cannot be packed into a space with perfect efficiency. Your calculations take into account the maximum packing efficiency of spheres.
Reasoning steps	Tell the model to explain its reasoning. This can sometimes improve the model's reasoning capability. Also called "thinking steps."	Explain your reasoning step-by-step.
Response format	The format that you want the response to be in. For example, you can tell the model to output the response in JSON, table, Markdown, paragraph, bulleted list, keywords, elevator pitch, and so on. Also called "structure," "presentation," or "layout."	Format your response in Markdown.
Recap	Concise repeat of the key points of the prompt, especially the constraints and response format, at the end of the prompt.	Don't give away the answer and provide hints instead. Always format your response in Markdown format.
Safeguards	Grounds the questions to the mission of the bot. Also called "safety rules."	N/A
Depending on the specific tasks at hand, you might choose to include or exclude some of the optional components. You can also adjust the ordering of the components and check how that can affect the response.

Sample prompt template
The following prompt template shows you an example of what a well-structured prompt might look like:

Sample prompt template:

<OBJECTIVE_AND_PERSONA>
You are a [insert a persona, such as a "math teacher" or "automotive expert"]. Your task is to...
</OBJECTIVE_AND_PERSONA>

<INSTRUCTIONS>
To complete the task, you need to follow these steps:
1.
2.
...
</INSTRUCTIONS>

------------- Optional Components ------------

<CONSTRAINTS>
Dos and don'ts for the following aspects
1. Dos
2. Don'ts
</CONSTRAINTS>

<CONTEXT>
The provided context
</CONTEXT>

<OUTPUT_FORMAT>
The output format must be
1.
2.
...
</OUTPUT_FORMAT>

<FEW_SHOT_EXAMPLES>
Here we provide some examples:
1. Example #1
Input:
Thoughts:
Output:
...
</FEW_SHOT_EXAMPLES>

<RECAP>
Re-emphasize the key aspects of the prompt, especially the constraints, output format, etc.
</RECAP>
Best practices
Prompt design best practices include the following:

Give clear and specific instructions
Include few-shot examples
Assign a role
Add contextual information
Use system instructions
Structure prompts
Instruct the model to explain its reasoning
Break down complex tasks
Experiment with parameter values
Prompt iteration strategies